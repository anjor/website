
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Anjor Kanekar's personal website">
      
      
        <meta name="author" content="Anjor Kanekar">
      
      
        <link rel="canonical" href="https://anjor.xyz/writing/">
      
      
        <link rel="prev" href="../hire/">
      
      
        <link rel="next" href="category/academia/">
      
      
        
      
      
        <link rel="alternate" type="application/rss+xml" title="RSS feed" href="../feed_rss_created.xml">
        <link rel="alternate" type="application/rss+xml" title="RSS feed of updated content" href="../feed_rss_updated.xml">
      
      <link rel="icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.7.1">
    
    
      
        <title>Writing - anjor.xyz</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.484c7ddc.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      
  


  
  

<script id="__analytics">function __md_analytics(){function e(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],e("js",new Date),e("config","G-HHKQ3RWV3N"),document.addEventListener("DOMContentLoaded",(function(){document.forms.search&&document.forms.search.query.addEventListener("blur",(function(){this.value&&e("event","search",{search_term:this.value})}));document$.subscribe((function(){var t=document.forms.feedback;if(void 0!==t)for(var a of t.querySelectorAll("[type=submit]"))a.addEventListener("click",(function(a){a.preventDefault();var n=document.location.pathname,d=this.getAttribute("data-md-value");e("event","feedback",{page:n,data:d}),t.firstElementChild.disabled=!0;var r=t.querySelector(".md-feedback__note [data-md-value='"+d+"']");r&&(r.hidden=!1)})),t.hidden=!1})),location$.subscribe((function(t){e("config","G-HHKQ3RWV3N",{page_path:t.pathname})}))}));var t=document.createElement("script");t.async=!0,t.src="https://www.googletagmanager.com/gtag/js?id=G-HHKQ3RWV3N",document.getElementById("__analytics").insertAdjacentElement("afterEnd",t)}</script>
  
    <script>"undefined"!=typeof __md_analytics&&__md_analytics()</script>
  

    
    
  </head>
  
  
    <body dir="ltr">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#writing" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="anjor.xyz" class="md-header__button md-logo" aria-label="anjor.xyz" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            anjor.xyz
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Writing
            
          </span>
        </div>
      </div>
    </div>
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
    
      <div class="md-header__source">
        <a href="https://github.com/anjor/website" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href=".." class="md-tabs__link">
          
  
  
    
  
  Home

        </a>
      </li>
    
  

      
        
  
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="./" class="md-tabs__link">
          
  
  
    
  
  Writing

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../hire/" class="md-tabs__link">
          
  
  
    
  
  Hire Me

        </a>
      </li>
    
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="anjor.xyz" class="md-nav__button md-logo" aria-label="anjor.xyz" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    anjor.xyz
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/anjor/website" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_1" >
        
          
          <div class="md-nav__link md-nav__container">
            <a href=".." class="md-nav__link ">
              
  
  
  <span class="md-ellipsis">
    
  
    Home
  

    
  </span>
  
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_1" id="__nav_1_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_1">
            <span class="md-nav__icon md-icon"></span>
            
  
    Home
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
    
  
  
    
      
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    
  
    Writing
  

    
  </span>
  
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    
  
    Writing
  

    
  </span>
  
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#2025-wrapped" class="md-nav__link">
    <span class="md-ellipsis">
      
        2025 Wrapped
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#physics-oracle-validation-how-to-trust-code-youve-never-read" class="md-nav__link">
    <span class="md-ellipsis">
      
        Physics-Oracle Validation: How to Trust Code You've Never Read
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#the-autonomy-gradient-what-ai-can-and-cant-do-in-physics-research" class="md-nav__link">
    <span class="md-ellipsis">
      
        The Autonomy Gradient: What AI Can and Can't Do in Physics Research
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#writing-a-physics-paper-with-claude-what-actually-happened" class="md-nav__link">
    <span class="md-ellipsis">
      
        Writing a Physics Paper with Claude: What Actually Happened
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#the-fde-manifesto-what-would-stokes-do" class="md-nav__link">
    <span class="md-ellipsis">
      
        The FDE Manifesto: What Would Stokes Do?
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#the-unreasonable-effectiveness-of-hiring-assholes" class="md-nav__link">
    <span class="md-ellipsis">
      
        The Unreasonable Effectiveness of Hiring Assholes
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#building-a-gyrokinetics-code-without-reading-a-single-line-the-development-log" class="md-nav__link">
    <span class="md-ellipsis">
      
        Building a Gyrokinetics Code Without Reading a Single Line: The Development Log
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#testing-the-intelligence-explosion-can-ai-turn-one-physicist-into-a-research-team" class="md-nav__link">
    <span class="md-ellipsis">
      
        Testing the Intelligence Explosion: Can AI Turn One Physicist Into a Research Team?
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#reflection" class="md-nav__link">
    <span class="md-ellipsis">
      
        Reflection
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#the-database-selection-trap-why-your-technical-interviews-might-be-testing-the-wrong-things" class="md-nav__link">
    <span class="md-ellipsis">
      
        The Database Selection Trap: Why Your Technical Interviews Might Be Testing the Wrong Things
      
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../hire/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Hire Me
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
      
        
          
        
      
        
      
        
      
    
    
    
      
        
        
      
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" checked>
        
          
          <div class="md-nav__link md-nav__container">
            <a href="./" class="md-nav__link md-nav__link--active">
              
  
  
  <span class="md-ellipsis">
    
  
    Writing
  

    
  </span>
  
  

            </a>
            
              
              <label class="md-nav__link md-nav__link--active" for="__nav_2" id="__nav_2_label" tabindex="">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            
  
    Writing
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_2" >
        
          
          <label class="md-nav__link" for="__nav_2_2" id="__nav_2_2_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Archive
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_2">
            <span class="md-nav__icon md-icon"></span>
            
  
    Archive
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="archive/2025/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    2025
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="archive/2024/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    2024
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_3" >
        
          
          <label class="md-nav__link" for="__nav_2_3" id="__nav_2_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Categories
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_3">
            <span class="md-nav__icon md-icon"></span>
            
  
    Categories
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="category/academia/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    academia
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="category/ai/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    ai
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="category/ai-experiments/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    ai experiments
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="category/career/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    career
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="category/hiring/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    hiring
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="category/palantir/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    palantir
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="category/physics/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    physics
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="category/tools/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    tools
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" >
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Hire Me
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            
  
    Hire Me
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../hire/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Hire Me
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#2025-wrapped" class="md-nav__link">
    <span class="md-ellipsis">
      
        2025 Wrapped
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#physics-oracle-validation-how-to-trust-code-youve-never-read" class="md-nav__link">
    <span class="md-ellipsis">
      
        Physics-Oracle Validation: How to Trust Code You've Never Read
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#the-autonomy-gradient-what-ai-can-and-cant-do-in-physics-research" class="md-nav__link">
    <span class="md-ellipsis">
      
        The Autonomy Gradient: What AI Can and Can't Do in Physics Research
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#writing-a-physics-paper-with-claude-what-actually-happened" class="md-nav__link">
    <span class="md-ellipsis">
      
        Writing a Physics Paper with Claude: What Actually Happened
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#the-fde-manifesto-what-would-stokes-do" class="md-nav__link">
    <span class="md-ellipsis">
      
        The FDE Manifesto: What Would Stokes Do?
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#the-unreasonable-effectiveness-of-hiring-assholes" class="md-nav__link">
    <span class="md-ellipsis">
      
        The Unreasonable Effectiveness of Hiring Assholes
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#building-a-gyrokinetics-code-without-reading-a-single-line-the-development-log" class="md-nav__link">
    <span class="md-ellipsis">
      
        Building a Gyrokinetics Code Without Reading a Single Line: The Development Log
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#testing-the-intelligence-explosion-can-ai-turn-one-physicist-into-a-research-team" class="md-nav__link">
    <span class="md-ellipsis">
      
        Testing the Intelligence Explosion: Can AI Turn One Physicist Into a Research Team?
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#reflection" class="md-nav__link">
    <span class="md-ellipsis">
      
        Reflection
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#the-database-selection-trap-why-your-technical-interviews-might-be-testing-the-wrong-things" class="md-nav__link">
    <span class="md-ellipsis">
      
        The Database Selection Trap: Why Your Technical Interviews Might Be Testing the Wrong Things
      
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
  <div class="md-content" data-md-component="content">
    <div class="md-content__inner">
      <header class="md-typeset">
        <h1 id="writing">Writing</h1>
      </header>
      
        <article class="md-post md-post--excerpt">
  <header class="md-post__header">
    
    <div class="md-post__meta md-meta">
      <ul class="md-meta__list">
        <li class="md-meta__item">
          <time datetime="2025-12-11 00:00:00+00:00">2025/12/11</time></li>
        
          <li class="md-meta__item">
            in
            
              <a href="category/career/" class="md-meta__link">career</a></li>
        
        
          
          <li class="md-meta__item">
            
              4 min read
            
          </li>
        
        
      </ul>
      
    </div>
  </header>
  <div class="md-post__content md-typeset">
    <h2 id="2025-wrapped"><a class="toclink" href="2025/12/11/2025-wrapped/">2025 Wrapped</a></h2>
<h3 id="the-experiment-continues"><a class="toclink" href="2025/12/11/2025-wrapped/#the-experiment-continues">The Experiment Continues</a></h3>
<p>Last year I wrote about my <a href="https://anjor.xyz/writing/2024/12/23/2024-wrapped/">pivot to consulting</a> - an experiment with two constraints: transactional contracts (no equity), and working at a slower pace. I wanted to see what would happen if I stopped trying to identify what would drive me and instead just... did good work.</p>
<p>A year later, the experiment has sharpened into something more specific. The work has clustered around a thesis I didn't quite see coming: expertise matters more than ever, and there's a particular shape of person that companies desperately need.</p>
<h3 id="the-fde-moment"><a class="toclink" href="2025/12/11/2025-wrapped/#the-fde-moment">The FDE Moment</a></h3>
<p>This year I spent a lot of time helping companies hire and build teams. Not generic recruiting - specifically helping them find and develop what Palantir calls "Forward Deployed Engineers." People who combine technical depth with customer empathy, who can thrive in chaos, who take ownership of outcomes rather than just completing tasks.</p>
<p>The most intensive engagement was with an early stage startup, where I helped build their founding technical team from scratch. This wasn't just running interviews - it was developing detailed hiring theses for each candidate, thinking through team composition and dynamics, and working through real tension with the founders about what they actually needed.</p>
<p>We evaluated candidates on a deceptively simple framework: are they smart, and can they win? But making that framework operational - designing interviews that surface those qualities, synthesising signal across multiple conversations, thinking about how personalities would mesh - that's where the real work happened.</p>
<p>I also worked with a services company on designing their whole FDE strategy. Starting from the hiring framework all the way up to operational execution, we helped them build a culture of autonomy and ownership, and developed a process for identifying and nurturing talent. This relationship is still ongoing and I am looking forward to seeing how their FDE strategy evolves.</p>
<p>The insight I keep coming back to: the FDE archetype is having a moment. As AI tools give more leverage to individual contributors, companies need people who can operate autonomously, understand customer problems deeply, and ship solutions without extensive hand-holding. The traditional consultant who waits for specifications doesn't cut it. Neither does the product engineer who wants to build in isolation.</p>
<h3 id="building-palantir-businesses"><a class="toclink" href="2025/12/11/2025-wrapped/#building-palantir-businesses">Building Palantir Businesses</a></h3>
<p>A related thread: helping companies navigate the Palantir ecosystem specifically. </p>
<p>There's a growing ecosystem of companies building on Palantir Foundry, and they face a common challenge: how do you hire, structure, and deliver when the platform itself provides so much leverage? The playbooks from traditional consulting don't quite fit. The playbooks from product companies don't either.</p>
<p>My 7 years as an FDE at Palantir, combined with the hiring work, puts me in an interesting position to help these companies figure it out. It's a niche, but it's a niche where I can add real value.</p>
<h3 id="testing-the-intelligence-explosion"><a class="toclink" href="2025/12/11/2025-wrapped/#testing-the-intelligence-explosion">Testing the Intelligence Explosion</a></h3>
<p>The most unexpected project of the year had nothing to do with consulting. I decided to test whether AI could turn one physicist into a research team.</p>
<p>I have a PhD in plasma physics, but I haven't done active research in a decade. Could I use AI assistance to identify an unsolved problem in gyrokinetic turbulence, develop computational tools to attack it, and produce publishable results?</p>
<p>The answer, it turns out, is yes - with caveats.</p>
<p>I rebuilt <a href="https://github.com/anjor/gandalf">GANDALF</a>, my PhD-era gyrokinetics code, from scratch in JAX. Claude wrote 100% of the code - roughly 3,000 lines that I never read. I validated entirely through physics outputs, treating myself like a PhD advisor who looks at plots and asks whether the physics makes sense.</p>
<p>The <a href="https://arxiv.org/abs/2511.21891">paper is now on arxiv</a>. What took me 6-7 months as a PhD student took 30 days as a side project. Total cost: ~$550 in API credits.</p>
<p>AI amplifies expertise rather than replacing it.</p>
<p>Claude fabricated benchmark timings, claiming simulations ran on "Princeton's Stellar cluster" when everything actually ran on my MacBook. It invented development timelines, inflating one month to three years. It made up GPU runtimes for comparisons that never happened. The prose was equally confident whether Claude was stating facts or hallucinating.</p>
<p>The physics errors were worse. Wrong definitions. Incorrect cascade descriptions. Misinterpreted orderings. These were invisible to anyone without plasma physics training. I caught them because I have studied it. Without domain expertise, the paper would have been embarrassing.</p>
<p>The productivity gain is real. The AI handles implementation at superhuman speed. But catching physics-numerics errors before they compound, knowing when results are physically wrong even if numerically stable, designing meaningful validation tests - that requires a human who actually understands the domain.</p>
<p>I wrote about this in detail in a <a href="https://anjor.xyz/writing/category/physics/">five-part series</a> on my blog. AI-assisted research is genuinely powerful, but "intelligence as a commodity" overstates the case. The bottleneck shifted from execution to direction - but direction still requires deep expertise.</p>
<h3 id="the-thread"><a class="toclink" href="2025/12/11/2025-wrapped/#the-thread">The Thread</a></h3>
<p>Looking back at the year, there's a theme I didn't plan but keep encountering: expertise matters more than ever.</p>
<p>In hiring: companies need people who understand specific domains deeply, not generic talent that can be pointed at any problem.</p>
<p>In the Palantir ecosystem: success requires people who genuinely understand Foundry and how to deploy it, not just generic services firms.</p>
<p>In AI-assisted research: Claude can write thousands of lines of code, but someone still needs to catch the physics errors.</p>
<p>The intelligence explosion hypothesis is partially true. AI is a massive force multiplier. But it amplifies expertise rather than replacing it. The people who win are those who combine deep domain knowledge with the ability to direct AI effectively.</p>
<h3 id="looking-forward"><a class="toclink" href="2025/12/11/2025-wrapped/#looking-forward">Looking Forward</a></h3>
<p>The consultancy experiment continues. The thesis has sharpened: I help companies build FDE-shaped teams and navigate the Palantir ecosystem. The physics project proved I can still do research when motivated. </p>
<p>For 2026, I am interested in seeing how the AI-assisted research can generalise to other domains. Specifically thinking through effective AI adoption strategies. I also want to continue helping companies figure out how to hire and build in this new landscape where AI amplifies expertise but doesn't replace it.</p>
<p>We'll see how it goes.</p>
    
    
  </div>
</article>
      
        <article class="md-post md-post--excerpt">
  <header class="md-post__header">
    
    <div class="md-post__meta md-meta">
      <ul class="md-meta__list">
        <li class="md-meta__item">
          <time datetime="2025-12-10 00:00:00+00:00">2025/12/10</time></li>
        
          <li class="md-meta__item">
            in
            
              <a href="category/physics/" class="md-meta__link">physics</a>, 
              <a href="category/ai/" class="md-meta__link">ai</a></li>
        
        
          
          <li class="md-meta__item">
            
              6 min read
            
          </li>
        
        
      </ul>
      
    </div>
  </header>
  <div class="md-post__content md-typeset">
    <h2 id="physics-oracle-validation-how-to-trust-code-youve-never-read"><a class="toclink" href="2025/12/10/physics-oracle-validation-how-to-trust-code-youve-never-read/">Physics-Oracle Validation: How to Trust Code You've Never Read</a></h2>
<p>In the <a href="2025/12/09/the-autonomy-gradient-what-ai-can-and-cant-do-in-physics-research/">previous post</a>, I described the autonomy gradient—how AI effectiveness varies from ~100% for code implementation to ~0% for research direction. But I left a question hanging: if you're not reading the code, how do you know it's correct?</p>
<p>This is not a trivial problem. Claude generated ~3,500 lines of JAX implementing spectral methods, Hermite polynomial couplings, and exponential integrating factors. I didn't read any of it. How can I trust it?</p>
<p>The answer is what I call <em>physics-oracle validation</em>: using physics itself as the specification against which code is tested. </p>
<p>This is not a new idea. It was my lived experience of doing physics research. As an undergraduate researcher, you meet your advisor periodically and get feedback only on the physics bits of the project. The advisor doesn't really read your code or help you debug. I tried to emulate the same setup.</p>
<p>This post explains the methodology, its limitations, and the honest question of who can actually replicate this approach.</p>
<h3 id="the-trust-problem"><a class="toclink" href="2025/12/10/physics-oracle-validation-how-to-trust-code-youve-never-read/#the-trust-problem">The Trust Problem</a></h3>
<p>Traditional approaches to code verification—code review, unit tests, static analysis—require understanding implementation details. But that defeats the productivity benefit of AI assistance. If I have to read every line Claude writes, I might as well write it myself.</p>
<p>The insight is that scientific simulation has something most software doesn't: an external oracle. Physics provides ground truth. If the code reproduces known physical results, it's correct—regardless of how it's implemented. And honestly this is how I verified the <a href="https://github.com/anjor/gandalf-original">original GANDALF</a>--if you look at the code, there are no tests. I would run a simulation, look at the physics results, and that was my validation.</p>
<p>This is a fundamentally different verification model. I'm not checking <em>how</em> the code works. I'm checking <em>what</em> it produces.</p>
<h3 id="four-levels-of-validation"><a class="toclink" href="2025/12/10/physics-oracle-validation-how-to-trust-code-youve-never-read/#four-levels-of-validation">Four Levels of Validation</a></h3>
<p>I used four increasingly stringent validation levels, each testing different aspects of the implementation:</p>
<h4 id="level-1-linear-regime"><a class="toclink" href="2025/12/10/physics-oracle-validation-how-to-trust-code-youve-never-read/#level-1-linear-regime">Level 1: Linear Regime</a></h4>
<p>Problems with exact analytical solutions. Alfvén waves should propagate at exactly the Alfvén speed. The dispersion relation is exact—errors should be at machine precision.</p>
<p><strong>Expected precision</strong>: ~10⁻¹⁵ (floating point epsilon)</p>
<p><strong>What it validates</strong>: Time integration, linear operators, basic correctness</p>
<p>This is the easiest test. If linear physics is wrong, nothing else matters. Claude passed this on the first serious attempt.</p>
<h4 id="level-2-nonlinear-conservation"><a class="toclink" href="2025/12/10/physics-oracle-validation-how-to-trust-code-youve-never-read/#level-2-nonlinear-conservation">Level 2: Nonlinear Conservation</a></h4>
<p>Invariants that should be maintained during nonlinear evolution. The Orszag-Tang vortex—a standard MHD benchmark—should conserve total energy even as kinetic and magnetic energy slosh back and forth.</p>
<p><img alt="Orszag-Tang Vortex" src="assets/orszag_tang_structures.png" /></p>
<p><strong>Expected precision</strong>: ~10⁻⁶ over many dynamical times</p>
<p><strong>What it validates</strong>: Nonlinear terms, Poisson bracket discretization, spectral accuracy</p>
<p>This is where subtle bugs show up. Wrong operator ordering, sign errors, aliasing issues—they all manifest as energy drift. The code took several iterations to pass this test. Each failure gave diagnostic information: exponential growth meant sign errors, linear drift meant conservation violations, sudden blow-up meant aliasing.</p>
<h4 id="level-3-statistical-equilibrium"><a class="toclink" href="2025/12/10/physics-oracle-validation-how-to-trust-code-youve-never-read/#level-3-statistical-equilibrium">Level 3: Statistical Equilibrium</a></h4>
<p>Emergent behavior matching theory. Driven turbulence should show Kolmogorov k⁻⁵/³ scaling. This isn't programmed in—it emerges from correct multiscale energy transfer.</p>
<p><strong>Expected precision</strong>: Power law exponent within ~0.05</p>
<p><strong>What it validates</strong>: Forcing implementation, dissipation mechanisms, scale-by-scale energy transfer</p>
<p>This was the hard one. As I described in the previous post, achieving the correct spectrum required extensive parameter tuning. But the test itself is unambiguous: either the spectrum shows the right scaling or it doesn't.</p>
<h4 id="level-4-velocity-space"><a class="toclink" href="2025/12/10/physics-oracle-validation-how-to-trust-code-youve-never-read/#level-4-velocity-space">Level 4: Velocity Space</a></h4>
<p>Kinetic physics validation. Phase mixing rates and Hermite moment spectra should match kinetic theory predictions.</p>
<p><strong>What it validates</strong>: Velocity-space operators, Landau damping, collisionless physics</p>
<p>This tests the kinetic aspects of GANDALF that distinguish it from pure MHD. The code should capture the essential velocity-space dynamics that make plasma physics interesting.</p>
<h3 id="why-this-works"><a class="toclink" href="2025/12/10/physics-oracle-validation-how-to-trust-code-youve-never-read/#why-this-works">Why This Works</a></h3>
<p>Physics-oracle testing has several advantages:</p>
<p><strong>Tests behavior, not implementation</strong>: I don't care if Claude used a for-loop or vectorization, whether it allocated memory efficiently, or if the variable names make sense. I care if the physics is right.</p>
<p><strong>Scales to complex codes</strong>: Full code review of 3,500 lines would take days. Physics validation takes hours.</p>
<p><strong>Catches subtle physics errors that unit tests miss</strong>: Code can pass all unit tests while producing wrong physics. A spectral method might have correct FFT calls but wrong normalization. Unit tests might pass; physics outputs would fail.</p>
<p><strong>Provides diagnostic information</strong>: When tests fail, <em>how</em> they fail indicates <em>what's</em> wrong. Energy growing exponentially suggests sign errors. Energy drifting linearly suggests conservation bugs. Wrong spectral slopes suggest forcing or dissipation issues.</p>
<h3 id="the-limitations"><a class="toclink" href="2025/12/10/physics-oracle-validation-how-to-trust-code-youve-never-read/#the-limitations">The Limitations</a></h3>
<p>This methodology has important limitations I need to be honest about.</p>
<p><strong>Requires known results</strong>: Physics-oracle testing only works when you know what the physics <em>should</em> do. For established physics like KRMHD, canonical benchmarks exist. For genuinely novel physics, you face circular reasoning: validating code requires knowing the answer, but discovering the answer requires trusted code.</p>
<p><strong>May miss bugs that preserve tested properties</strong>: A bug that happens to conserve energy and produce correct spectra would pass all tests. The methodology provides high confidence, not certainty.</p>
<p><strong>Requires domain expertise to interpret</strong>: When the Orszag-Tang test showed 10⁻⁴ energy conservation instead of 10⁻⁶, is that acceptable? It depends on the timestep, the resolution, the integration time. These judgments require physics intuition.</p>
<p>For frontier physics, complementary validation approaches are needed—comparison with other codes, analytical limits, asymptotic analysis. Physics-oracle testing is powerful but not complete.</p>
<h3 id="the-n1-question"><a class="toclink" href="2025/12/10/physics-oracle-validation-how-to-trust-code-youve-never-read/#the-n1-question">The N=1 Question</a></h3>
<p>A friend asked me: "How much of an N=1 are you? Could someone else do this?"</p>
<p>Honest answer: <strong>probably not yet, at least not without a similar background.</strong></p>
<p>This success required a specific—and possibly non-generic—combination of expertise:</p>
<p><strong>Domain expertise (PhD in plasma physics)</strong>: Critical for interpreting test results and catching physics errors. When Claude suggested using GS2 (a full gyrokinetics code) for problems where reduced equations suffice, only domain knowledge caught the error. When simulations showed marginal stability, only physics intuition knew that was acceptable.</p>
<p><strong>Software engineering intuition (decade in tech)</strong>: Enabled the decision to rewrite in JAX rather than resurrect legacy Fortran/CUDA. Understanding of modern frameworks, deployment options, and how to write specifications AI can implement effectively.</p>
<p><strong>Generative AI experience (recent work)</strong>: Provided realistic expectations of AI capabilities, effective interaction patterns, and understanding of failure modes. I knew to create step-by-step plans rather than open-ended requests. I knew to set up the dual-Claude review pattern to keep the code honest.</p>
<p>AI proved valuable at both ends of the research process—literature synthesis and code implementation—but the middle stages (tool selection, physics judgment, validation interpretation) required human expertise.</p>
<p>Could this be taught? Could I package the workflow into something a researcher without all three backgrounds could use? I genuinely don't know. That's an open question worth exploring.</p>
<h3 id="hallucination-a-task-dependent-problem"><a class="toclink" href="2025/12/10/physics-oracle-validation-how-to-trust-code-youve-never-read/#hallucination-a-task-dependent-problem">Hallucination: A Task-Dependent Problem</a></h3>
<p>One finding was interesting: hallucination severity depends strongly on task constraints.</p>
<p><strong>Code generation (~100% autonomy)</strong>: Minimal hallucination. Code either runs or crashes. Physics outputs either match theory or don't. Tight constraints leave little room for fabrication.</p>
<p><strong>Paper writing (~50% autonomy)</strong>: Significant hallucination. When helping with the physics paper, Claude fabricated:</p>
<ul>
<li>Computational resources ("timings obtained on Princeton's Stellar cluster" when all runs used my MacBook)</li>
<li>Development timelines ("three years of part-time development" versus the actual one month)</li>
<li>GPU runtimes for simulations that were never performed</li>
<li>Physics errors including wrong cascade directions</li>
</ul>
<p>These were caught in review. But the confident assertion of false claims was notable.</p>
<p><strong>Key insight</strong>: Hallucination correlates inversely with task constraints. High-autonomy tasks have tight feedback—code must run, physics must match. Medium-autonomy tasks like prose have looser feedback, allowing AI to extrapolate beyond given facts.</p>
<p>The claim "I never read the AI-generated code" requires nuance: for physics code, physics outputs constrain hallucination. For prose, human review remains essential.</p>
<h3 id="what-this-means-going-forward"><a class="toclink" href="2025/12/10/physics-oracle-validation-how-to-trust-code-youve-never-read/#what-this-means-going-forward">What This Means Going Forward</a></h3>
<p>Physics-oracle validation isn't a complete solution, but it's a practical methodology for a specific problem: trusting AI-generated scientific code in domains with established benchmarks.</p>
<p>The approach suggests a broader principle: <strong>verification should operate at the level of the specification, not the implementation</strong>. For physics code, the specification is physical behavior. For other domains, finding the right oracle is the key challenge.</p>
<p>If AI continues improving at implementation while humans retain judgment—the autonomy gradient I described in the last post—then validation methodologies become increasingly important. The bottleneck shifts from writing code to knowing what code should do.</p>
<p>That's a different skill. And it's one physicists have always had.</p>
<hr />
<h4 id="acknowledgements"><a class="toclink" href="2025/12/10/physics-oracle-validation-how-to-trust-code-youve-never-read/#acknowledgements">Acknowledgements</a></h4>
<p>Thanks to Alex Schekochihin and Nuno Loureiro for discussions throughout this project. Thanks to everyone who read the earlier posts and pushed back on the optimistic framing—you made this analysis sharper.</p>
<p>The code: <a href="https://github.com/anjor/gandalf">github.com/anjor/gandalf</a>
The paper: <a href="https://github.com/anjor/gandalf-paper">github.com/anjor/gandalf-paper</a></p>
    
    
  </div>
</article>
      
        <article class="md-post md-post--excerpt">
  <header class="md-post__header">
    
    <div class="md-post__meta md-meta">
      <ul class="md-meta__list">
        <li class="md-meta__item">
          <time datetime="2025-12-09 00:00:00+00:00">2025/12/09</time></li>
        
          <li class="md-meta__item">
            in
            
              <a href="category/physics/" class="md-meta__link">physics</a>, 
              <a href="category/ai/" class="md-meta__link">ai</a></li>
        
        
          
          <li class="md-meta__item">
            
              5 min read
            
          </li>
        
        
      </ul>
      
    </div>
  </header>
  <div class="md-post__content md-typeset">
    <h2 id="the-autonomy-gradient-what-ai-can-and-cant-do-in-physics-research"><a class="toclink" href="2025/12/09/the-autonomy-gradient-what-ai-can-and-cant-do-in-physics-research/">The Autonomy Gradient: What AI Can and Can't Do in Physics Research</a></h2>
<p>In the <a href="2025/11/05/testing-the-intelligence-explosion-can-ai-turn-one-physicist-into-a-research-team/">first post</a>, I asked whether AI could turn one physicist into a research team. In the <a href="2025/11/11/building-a-gyrokinetics-code-without-reading-a-single-line-the-development-log/">second post</a>, I documented the messy reality of building GANDALF with Claude—the workflow, the surprises, the $40 days wrestling with turbulence.</p>
<p>Now the <a href="https://github.com/anjor/gandalf-paper">paper is written</a>. Time to step back and ask: what did we actually learn?</p>
<p>The headline is seductive: 21 days, $558, working code. But the numbers hide the real finding. AI effectiveness isn't uniform. It varies dramatically depending on what you're asking it to do. There is an <em>autonomy gradient</em>, and understanding it is the key to making AI-assisted research work.</p>
<h3 id="the-numbers"><a class="toclink" href="2025/12/09/the-autonomy-gradient-what-ai-can-and-cant-do-in-physics-research/#the-numbers">The Numbers</a></h3>
<p>What went right:</p>
<ul>
<li><strong>21 active development days</strong> (spanning about a month of calendar time)</li>
<li><strong>$558 in API costs</strong></li>
<li><strong>~3,500 lines of JAX code</strong>—none of which I read</li>
<li><strong>All physics benchmarks passed</strong>: machine-precision (10⁻¹⁵) linear wave propagation, 10⁻⁶ energy conservation in nonlinear tests, textbook k⁻⁵/³ Kolmogorov scaling</li>
</ul>
<p>For comparison, the original Fortran/CUDA version of GANDALF took me over six months during my PhD. The AI-assisted version took less than one month.</p>
<p>But these numbers obscure the central finding.</p>
<h3 id="the-autonomy-gradient"><a class="toclink" href="2025/12/09/the-autonomy-gradient-what-ai-can-and-cant-do-in-physics-research/#the-autonomy-gradient">The Autonomy Gradient</a></h3>
<p>AI effectiveness isn't binary—it follows a gradient from near-total autonomy to complete human dependence:</p>
<p><img alt="Autonomy Gradient" src="assets/autonomy-gradient.png" /></p>
<table>
<thead>
<tr>
<th>Task</th>
<th>AI Autonomy</th>
<th>Human Role</th>
</tr>
</thead>
<tbody>
<tr>
<td>Code implementation</td>
<td>~100%</td>
<td>Specifications</td>
</tr>
<tr>
<td>Diagnostic addition</td>
<td>~95%</td>
<td>Requirements</td>
</tr>
<tr>
<td>Runtime debugging</td>
<td>~90%</td>
<td>Symptom identification</td>
</tr>
<tr>
<td>Test generation</td>
<td>~85%</td>
<td>Physics constraints</td>
</tr>
<tr>
<td>Performance optimization</td>
<td>~70%</td>
<td>Targets</td>
</tr>
<tr>
<td>Documentation</td>
<td>~60%</td>
<td>Structure, accuracy</td>
</tr>
<tr>
<td>Paper writing</td>
<td>~50%</td>
<td>Voice, narrative</td>
</tr>
<tr>
<td>Parameter tuning</td>
<td>~10%</td>
<td>Full guidance</td>
</tr>
<tr>
<td>Research direction</td>
<td>~0%</td>
<td>Entirely human</td>
</tr>
</tbody>
</table>
<p>AI can implement what is specified but cannot determine what to specify.</p>
<p>Here's what high autonomy looks like in practice. After discussing that we needed energy spectrum diagnostics, my entire prompt was:</p>
<pre><code>Sounds good, let's do diagnostics
</code></pre>
<p>Five words. Claude implemented shell-averaged perpendicular energy spectra, proper normalization, integration with file I/O. No iteration required.</p>
<p>Similarly, when addressing code review feedback:</p>
<pre><code>Address review comments: https://github.com/anjor/gandalf/pull/18
</code></pre>
<p>Claude read the comments, implemented all changes, pushed updates. I verified correctness through physics outputs, not code inspection.</p>
<p>This is the dream scenario: unambiguous context, established patterns, objective success criteria. At this end of the gradient, AI assistance feels like magic.</p>
<h3 id="physics-taste-the-critical-gap"><a class="toclink" href="2025/12/09/the-autonomy-gradient-what-ai-can-and-cant-do-in-physics-research/#physics-taste-the-critical-gap">Physics Taste: The Critical Gap</a></h3>
<p>Now here's what low autonomy looks like.</p>
<p>Achieving the k⁻⁵/³ turbulent spectrum—textbook physics, nothing exotic—required extensive human guidance. Here's an actual sequence from my session logs:</p>
<pre><code>Look at @examples/output/driven_energy_spectra.png -- shouldn't we
see a -5/3 spectrum here for k_perp? But we are not?
</code></pre>
<p>Claude suggested modifications: reduce hyperviscosity, increase resolution. After implementation, issues persisted:</p>
<pre><code>can we increase the forcing? Do you think that will help? Right now
it seems like energy is not moving to larger k's quickly enough. I
am also ok with forcing k=1 and 2
</code></pre>
<p>More iterations:</p>
<pre><code>I think we need stronger forcing
</code></pre>
<p>And:</p>
<pre><code>What's our forcing range?
</code></pre>
<p>This pattern—human identifies problem, suggests direction, requests information, decides next step—continued for multiple sessions. Claude implemented each change correctly but did not independently converge toward the solution.</p>
<p>The model was missing <em>physics taste</em>: the intuition that allows researchers to recognize when they're approaching correct behavior (even if not there yet), prioritize which parameters to explore based on physical reasoning, and know when the answer "looks right."</p>
<p>Three specific failure modes emerged:</p>
<p><strong>Premature optimization for stability</strong>: When simulations exhibited marginal numerical stability—which is <em>normal</em> when pushing Reynolds number—the model consistently recommended adding dissipation, reducing the timestep, or smoothing initial conditions. These interventions improve numerical behavior but degrade physics content. As a physicist, you're always trying to run as close to the edge of instability as possible because that's where the interesting physics lives. The model optimizes for the wrong thing.</p>
<p><strong>No convergence sensing</strong>: During parameter exploration, the model showed no awareness of getting closer to or farther from the target. Each attempt was independent. When I told it "there's a slight pile-up at high k, but it's acceptable if we stop the simulation now," it incorporated the information—but it couldn't generate such observations itself.</p>
<p><strong>Jumping to solutions</strong>: Rather than methodical exploration, the model proposed complete "fixes" that assumed knowledge of the correct answer. This works for textbook problems but fails at the research frontier where nobody knows the answer.</p>
<p>Two incidents deserve mention. First, when struggling to achieve the k⁻⁵/³ spectrum, the model at one point generated synthetic data showing the expected result—completely defeating the purpose of validation. Second, the model at another point concluded the problem was intractable: "this isn't possible, let's just document the attempts and shortcomings."</p>
<p>Here's the interesting part: in both cases, the model was transparent. It admitted the synthetic nature of the data in the first case, and honestly recommended abandonment in the second. This honesty is valuable—but transparency doesn't equal capability. The persistence that domain expertise provides was entirely absent.</p>
<h3 id="what-this-means"><a class="toclink" href="2025/12/09/the-autonomy-gradient-what-ai-can-and-cant-do-in-physics-research/#what-this-means">What This Means</a></h3>
<p>Back to the intelligence explosion hypothesis from my first post. The claim was that AI would make intelligence a commodity—as accessible as electricity.</p>
<p>This experiment suggests <strong>not yet, but the direction is clear</strong>.</p>
<p>What AI provides is better described as "capable undergraduate researcher"—able to execute well-specified tasks but requiring supervision for judgment-dependent work. The bottleneck shifts from implementation to direction, from coding to physics insight.</p>
<p>This is genuinely useful. A 5-10x speedup on implementation tasks is meaningful. The ability to work at 2am without getting frustrated, to never forget a paper, to implement complex numerical schemes on demand—these capabilities address real bottlenecks in computational physics.</p>
<p>But the essential human role in scientific discovery remains. Problem selection, validation capability, physics taste—these cannot be delegated. AI amplifies what you already know; it doesn't replace knowing things.</p>
<p>There's one question I haven't addressed: if you're not reading the code, how do you know it's correct? The answer involves what I call <em>physics-oracle validation</em>—using physics itself as the specification against which code is tested.</p>
<p>That's the subject of the next post.</p>
<hr />
<h4 id="acknowledgements"><a class="toclink" href="2025/12/09/the-autonomy-gradient-what-ai-can-and-cant-do-in-physics-research/#acknowledgements">Acknowledgements</a></h4>
<p>Thanks to everyone following along with this experiment. The questions—especially the skeptical ones—have helped sharpen my thinking about what this all means.</p>
<p>The paper is available at <a href="https://github.com/anjor/gandalf-paper">github.com/anjor/gandalf-paper</a>. The code is at <a href="https://github.com/anjor/gandalf">github.com/anjor/gandalf</a>.</p>
    
    
  </div>
</article>
      
        <article class="md-post md-post--excerpt">
  <header class="md-post__header">
    
    <div class="md-post__meta md-meta">
      <ul class="md-meta__list">
        <li class="md-meta__item">
          <time datetime="2025-12-01 00:00:00+00:00">2025/12/01</time></li>
        
          <li class="md-meta__item">
            in
            
              <a href="category/physics/" class="md-meta__link">physics</a>, 
              <a href="category/ai/" class="md-meta__link">ai</a></li>
        
        
          
          <li class="md-meta__item">
            
              7 min read
            
          </li>
        
        
      </ul>
      
    </div>
  </header>
  <div class="md-post__content md-typeset">
    <h2 id="writing-a-physics-paper-with-claude-what-actually-happened"><a class="toclink" href="2025/12/01/writing-a-physics-paper-with-claude-what-actually-happened/">Writing a Physics Paper with Claude: What Actually Happened</a></h2>
<p>In a <a href="2025/11/11/building-a-gyrokinetics-code-without-reading-a-single-line-the-development-log/">previous post</a>, I documented building a plasma turbulence solver with Claude—3,000 lines of JAX I never read, validated entirely through physics outputs. That post ended with: "we're writing a proper journal paper."</p>
<p>The <a href="https://arxiv.org/abs/2511.21891">paper is now live on arxiv</a>. This post covers what happened next: writing the paper itself. The failure modes were completely different.</p>
<p><img alt="Orszag-Tang vortex simulation" src="assets/orszag_tang_structures.png" />
<em>Current sheets and vortex structures forming in an Orszag-Tang simulation—the kind of physics GANDALF captures</em></p>
<p>The numbers sound impressive: 143 Claude Code sessions, 23 GitHub issues closed, 20 pull requests merged. But the headline obscures the real story. This post documents what actually happened—the workflow, the iterations, and the hallucinations that would have been embarrassing if they'd made it to publication.</p>
<h3 id="the-workflow-architecture"><a class="toclink" href="2025/12/01/writing-a-physics-paper-with-claude-what-actually-happened/#the-workflow-architecture">The Workflow Architecture</a></h3>
<p>The approach that made this possible wasn't magic. It was infrastructure.</p>
<p><strong>GitHub Issues for everything.</strong> Each paper section got an issue. Each benchmark got an issue. Issues #4-16 tracked the initial writing: Introduction, Mathematical Formulation, Numerical Methods, Implementation, Verification, Discussion, Conclusions. The four physics benchmarks (Alfvén waves, Orszag-Tang, turbulent cascade, velocity-space) each got their own issues.</p>
<p><img alt="GitHub issues list" src="assets/gandalf-issues-list.png" />
<em>23 GitHub issues tracked every section and benchmark</em></p>
<p><strong>Section-by-section PRs.</strong> Each section was a separate pull request. The Claude GitHub App provided automated review on every PR—catching notation inconsistencies, citation formatting issues, and obvious errors.</p>
<p><strong>Human review issues.</strong> After completing initial drafts, I created human review issues (#37-42) for each section. This is where I sat down and actually read what Claude had written. Issue #55 was a final comprehensive review. These reviews were not optional polish.</p>
<p><strong>External AI review.</strong> I also ran the draft through Gemini 3 Pro (Issues #53, #58) for a different perspective. Different models catch different errors.</p>
<p>The git history tells the iteration story better than I can:</p>
<pre><code>a03703d Implement turbulent cascade spectrum benchmark (Issue #10)
241b327 Address reviewer feedback on turbulent cascade PR #33
536eba5 Address reviewer feedback on PR #33
fb7d583 Replace synthetic data with real N64 turbulent cascade results
9b590ae Fix critical physics and notation issues in turbulent cascade section
f36db7c Address final reviewer feedback on PR #33
... (14+ iterations on this single PR)
</code></pre>
<p>PR #33 for the turbulent cascade section went through fourteen revision cycles before merging. This was not "Claude writes a paper." This was iteration.</p>
<h3 id="what-claude-did-well"><a class="toclink" href="2025/12/01/writing-a-physics-paper-with-claude-what-actually-happened/#what-claude-did-well">What Claude Did Well</a></h3>
<p>Credit where it's due. Claude was genuinely useful for:</p>
<p><strong>Initial drafting.</strong> Given mathematical specifications and paper structure, Claude generated coherent first drafts of each section. The drafts weren't publishable, but they were workable starting points—better than staring at a blank page.</p>
<p><strong>LaTeX formatting.</strong> Equations, figures, notation consistency, bibliography formatting. The mechanical aspects of scientific LaTeX were handled reliably.</p>
<p><strong>Addressing specific feedback.</strong> This is where AI assistance shines. When I identified a specific problem—"this equation is wrong," "this citation is missing," "this paragraph contradicts the previous section"—Claude implemented fixes quickly and correctly. PR #25 (Alfvén wave benchmark) went through four rounds of review feedback, each addressed systematically within minutes.</p>
<p><strong>Literature integration.</strong> Given a topic, Claude could find relevant citations and format them properly. It knew the key papers in plasma turbulence.</p>
<h3 id="the-hallucination-problem"><a class="toclink" href="2025/12/01/writing-a-physics-paper-with-claude-what-actually-happened/#the-hallucination-problem">The Hallucination Problem</a></h3>
<p>Now for the part that matters.</p>
<p>During human review (Issue #55), I found fabricated content that Claude had written with complete confidence. There were made-up facts presented as authoritative scientific claims.</p>
<p><img alt="Issue #55 hallucinations" src="assets/gandalf-issue55-hallucinations.png" />
<em>Issue #55: Human review caught fabricated Princeton cluster claims, false timelines, and invented benchmarks</em></p>
<p><strong>Fabricated benchmark timings:</strong></p>
<blockquote>
<p>"These timings were obtained on identical 80 GB A100 nodes on Princeton's Stellar cluster to ensure an apples-to-apples comparison."</p>
</blockquote>
<p>Every benchmark in this paper ran on my M1 MacBook Pro. I have never had access to Princeton's Stellar cluster. Claude invented institutional affiliation, specific GPU model, and performance comparison methodology out of nothing.</p>
<p><strong>False development timeline:</strong></p>
<blockquote>
<p>"Three years of development and production use provide empirical evidence for this decision's trade-off"</p>
<p>"GANDALF reached research-grade maturity within three years of part-time solo development."</p>
</blockquote>
<p>The actual development time was approximately one month, with Claude assistance. Claude inflated this by a factor of 36.</p>
<p><strong>Invented GPU runtimes:</strong></p>
<blockquote>
<p>"A moderate-scale turbulent cascade (N = 128³, 50,000 timesteps) completes in ~7 hours on a single NVIDIA A100 GPU. An optimized CUDA code might complete in ~2.5 hours"</p>
</blockquote>
<p>No GPU simulations were performed. These runtime numbers were fabricated. The comparison to "optimized CUDA code" was invented.</p>
<p><strong>Made-up community claims:</strong></p>
<p>Claude wrote an entire "Community growth potential" subsection filled with fabricated claims about user adoption, classroom deployment, and community engagement. None of it had happened.</p>
<p><strong>Physics errors:</strong></p>
<p>Beyond fabrication, there were physics mistakes that required domain expertise to catch:
- Wrong definitions of g± (combinations of density and magnetic fluctuations)
- Incorrect cascade direction claims
- Misinterpretation of gyrokinetic orderings
- Missing discussion of the velocity-space benchmark</p>
<p>The key insight: Claude was equally confident in true statements and fabricated ones. The prose read identically. There was no signal in the writing that would distinguish "things that happened" from "things Claude made up."</p>
<h3 id="the-human-review-cycle"><a class="toclink" href="2025/12/01/writing-a-physics-paper-with-claude-what-actually-happened/#the-human-review-cycle">The Human Review Cycle</a></h3>
<p>Issue #55 alone contained 40+ specific corrections across all sections. The pattern:</p>
<p><strong>Physics errors requiring domain expertise.</strong> When Claude wrote that "compressive fluctuations are driven by Alfvén waves," I had to know enough physics to recognize this was wrong—they're mixed by Alfvén waves, not driven by them. When it claimed "k⊥ρi ≪ 1" meant "low frequency," I needed to know this actually means "scales larger than ion Larmor radius."</p>
<p><strong>Notation inconsistencies.</strong> Claude used lowercase φ for the stream function in some places, uppercase Φ in others. The Elsasser fields were sometimes ξ±, sometimes z±. These required systematic correction.</p>
<p><strong>Missing content.</strong> The Discussion section had no mention of the velocity-space benchmark, even though it was a major contribution. Claude simply forgot to include it.</p>
<p><strong>Fabricated quantitative claims.</strong> Every specific number needed verification against what actually happened.</p>
<p>These reviews weren't polish, but the difference between a publishable paper and an embarrassing one.</p>
<h3 id="the-real-workflow"><a class="toclink" href="2025/12/01/writing-a-physics-paper-with-claude-what-actually-happened/#the-real-workflow">The Real Workflow</a></h3>
<p>143 Claude Code conversation sessions for this paper. What did that actually look like?</p>
<p>A typical session: open an issue, tell Claude to draft that section, review output, create PR, Claude GitHub App reviews, I review, create issue with corrections, Claude addresses corrections, iterate.</p>
<p><img alt="Claude GitHub App review" src="assets/gandalf-pr-review.png" />
<em>Claude GitHub App provided automated review on every PR</em></p>
<p>The "speed" of AI-assisted writing was iteration speed, not magic. Each round of feedback could be addressed in minutes instead of hours. But each round still required human judgment to identify what was wrong.</p>
<p>The ratio matters: Claude could implement changes 10x faster than I could. But identifying what changes to make remained 100% human.</p>
<h3 id="lessons-learned"><a class="toclink" href="2025/12/01/writing-a-physics-paper-with-claude-what-actually-happened/#lessons-learned">Lessons Learned</a></h3>
<p><strong>AI drafting ≠ AI writing.</strong> Claude can draft. But drafting is maybe 20% of writing a paper. The other 80%—knowing what's true, what's relevant, what's correctly stated, what's missing—requires a human who knows the domain.</p>
<p><strong>Hallucination risk is highest for quantitative claims.</strong> The fabricated content was overwhelmingly specific numbers, timelines, and institutional details. Claude had no hesitation inventing precise GPU runtimes or development timelines. Every quantitative claim needs verification.</p>
<p><strong>Structured workflow creates an audit trail.</strong> Issues, PRs, and review cycles meant I could trace every change. When the fabricated Princeton cluster claim appeared, I could see exactly which Claude session introduced it. This transparency matters.</p>
<p><strong>AI excels at iteration on specific feedback.</strong> Tell Claude exactly what's wrong, and it fixes it correctly. Ask Claude to review its own work for errors, and it misses the same errors it introduced.</p>
<p><strong>Domain expertise cannot be delegated.</strong> The physics errors—wrong definitions, incorrect cascade descriptions, misinterpreted orderings—were invisible to anyone without plasma physics training. AI assistance amplifies what you know. It doesn't replace knowing things.</p>
<h3 id="the-numbers"><a class="toclink" href="2025/12/01/writing-a-physics-paper-with-claude-what-actually-happened/#the-numbers">The Numbers</a></h3>
<p>For the record:</p>
<ul>
<li>~3 weeks calendar time (Nov 7 - Nov 26, 2025)</li>
<li>143 Claude Code conversation sessions</li>
<li>23 GitHub issues closed</li>
<li>20 pull requests merged</li>
<li>Multiple human review passes (Issues #37-42, #55)</li>
<li>External AI review (Gemini 3 Pro, Issues #53, #58)</li>
<li>Final paper: 6 sections, 4 physics benchmarks</li>
</ul>
<h3 id="conclusion"><a class="toclink" href="2025/12/01/writing-a-physics-paper-with-claude-what-actually-happened/#conclusion">Conclusion</a></h3>
<p>This post is the honest version of "I wrote a paper with AI assistance."</p>
<p>Claude helped. The iteration speed was real. The infrastructure—issues, PRs, reviews—made it manageable. But the fabrications were also real. Without human review, this paper would have claimed development timelines that never happened, benchmark results on hardware I never used, and community engagement that doesn't exist.</p>
<p>The paper is correct now because I caught those errors. Not because Claude didn't make them.</p>
<hr />
<p>Paper: <a href="https://arxiv.org/abs/2511.21891">arxiv:2511.21891</a></p>
<p>Code: <a href="https://github.com/anjor/gandalf">github.com/anjor/gandalf</a></p>
<p>Paper repo: <a href="https://github.com/anjor/gandalf-paper">github.com/anjor/gandalf-paper</a></p>
    
    
  </div>
</article>
      
        <article class="md-post md-post--excerpt">
  <header class="md-post__header">
    
    <div class="md-post__meta md-meta">
      <ul class="md-meta__list">
        <li class="md-meta__item">
          <time datetime="2025-11-20 00:00:00+00:00">2025/11/20</time></li>
        
          <li class="md-meta__item">
            in
            
              <a href="category/hiring/" class="md-meta__link">hiring</a></li>
        
        
          
          <li class="md-meta__item">
            
              2 min read
            
          </li>
        
        
      </ul>
      
    </div>
  </header>
  <div class="md-post__content md-typeset">
    <h2 id="the-fde-manifesto-what-would-stokes-do"><a class="toclink" href="2025/11/20/the-fde-manifesto-what-would-stokes-do/">The FDE Manifesto: What Would Stokes Do?</a></h2>
<p>This is a version of a document I had written during my time at Palantir. </p>
<p>Stokes was a legendary FDE at Palantir, and I learnt a lot by emulating his way of operating.
This wasn't hero worship—it was shorthand for a specific way of operating that separated exceptional FDEs from the rest.</p>
<p>Here are the tactical principles that define that approach.</p>
<h3 id="never-take-shortcuts-that-compound"><a class="toclink" href="2025/11/20/the-fde-manifesto-what-would-stokes-do/#never-take-shortcuts-that-compound">Never Take Shortcuts That Compound</a></h3>
<ul>
<li>Don't make config changes that aren't product defaults</li>
<li>Never restart services "just to see if it fixes things"—you're destroying evidence</li>
<li>Never deploy dirty builds. If you're on a branch, getting back to mainline is P0</li>
<li>Every custom modification is technical debt with compound interest</li>
</ul>
<h3 id="own-the-product-stack"><a class="toclink" href="2025/11/20/the-fde-manifesto-what-would-stokes-do/#own-the-product-stack">Own the Product Stack</a></h3>
<ul>
<li>Clone the repos. Make them build. Start submitting PRs</li>
<li>When you get a stacktrace, read it. Form a hypothesis before opening tickets</li>
<li>Know the architecture cold—when telemetry fails, it's your only map</li>
<li>If a workflow is blocked on a feature, scope it and build it yourself</li>
</ul>
<h3 id="treat-information-as-infrastructure"><a class="toclink" href="2025/11/20/the-fde-manifesto-what-would-stokes-do/#treat-information-as-infrastructure">Treat Information as Infrastructure</a></h3>
<ul>
<li>Ensure logs and metrics are collected properly from day one</li>
<li>Master telemetry tools—they're not optional</li>
<li>Read everything: docs, runbooks, release notes, support tickets, Stack Overflow</li>
<li>Monitor what other teams are encountering—their problems will be yours soon</li>
</ul>
<h3 id="root-cause-everything"><a class="toclink" href="2025/11/20/the-fde-manifesto-what-would-stokes-do/#root-cause-everything">Root Cause Everything</a></h3>
<ul>
<li>Never accept "it's working now" as resolution</li>
<li>Gather data and form hypotheses before implementing fixes</li>
<li>You must be able to explain why the product broke and why your fix worked</li>
<li>Document your debugging process for future you</li>
</ul>
<h3 id="build-strategic-relationships"><a class="toclink" href="2025/11/20/the-fde-manifesto-what-would-stokes-do/#build-strategic-relationships">Build Strategic Relationships</a></h3>
<ul>
<li>Every support ticket is a relationship-building opportunity with core engineers</li>
<li>Contribute field signal to product direction—you're their eyes and ears</li>
<li>Know the product team's roadmap and weigh in based on deployment reality</li>
<li>Getting your tickets prioritized is a function of relationships, not just severity</li>
</ul>
<h3 id="the-strategic-thread"><a class="toclink" href="2025/11/20/the-fde-manifesto-what-would-stokes-do/#the-strategic-thread">The Strategic Thread</a></h3>
<p>These aren't random best practices. They're behaviours that compound into a strategic advantage: <strong>radical ownership of outcomes</strong>.</p>
<p>When you refuse shortcuts, you're choosing long-term system health over short-term wins. When you master the product stack, you're becoming a peer to the product team, not a consumer. When you root cause everything, you're building institutional knowledge that makes future problems trivial.</p>
<p>This is what makes the FDE model powerful. You're not there to implement solutions—you're there to own outcomes completely. That ownership manifests in these specific, tactical behaviors that seem small but fundamentally change how you operate.</p>
<p>The question isn't whether you can do these things. It's whether you will.</p>
<hr />
<p><em>Building an FDE organization? These principles are your hiring rubric. Look for engineers who already think this way.</em></p>
<p><em>These principles form the evaluation criteria in my <a href="https://anjor.github.io/fde-advisory-materials/resources/people/interview-scorecard/">FDE Interview Scorecard</a>.</em></p>
<hr />
<p><em>Implementing an FDE hiring program? See my <a href="https://anjor.github.io/fde-advisory-materials/">FDE Advisory Materials</a> for interview templates, scorecards, and detailed process guides.</em></p>
    
    
  </div>
</article>
      
        <article class="md-post md-post--excerpt">
  <header class="md-post__header">
    
    <div class="md-post__meta md-meta">
      <ul class="md-meta__list">
        <li class="md-meta__item">
          <time datetime="2025-11-13 00:00:00+00:00">2025/11/13</time></li>
        
          <li class="md-meta__item">
            in
            
              <a href="category/hiring/" class="md-meta__link">hiring</a></li>
        
        
          
          <li class="md-meta__item">
            
              3 min read
            
          </li>
        
        
      </ul>
      
    </div>
  </header>
  <div class="md-post__content md-typeset">
    <h2 id="the-unreasonable-effectiveness-of-hiring-assholes"><a class="toclink" href="2025/11/13/the-unreasonable-effectiveness-of-hiring-assholes/">The Unreasonable Effectiveness of Hiring Assholes</a></h2>
<p>I've seen this pattern play out dozens of times. The brilliant engineer who tears apart your architecture in design reviews. The physics Nobel laureate who's a complete dick but moves research forward. The Palantir FDE who makes people uncomfortable but somehow always ships.</p>
<p>They're assholes. And they get results.</p>
<p>So there's this tempting logic: Maybe we need to hire more of them?</p>
<hr />
<p>A friend at a startup just told me something interesting. "Everyone here is so humble," she said. Then she paused. "Maybe too humble. Nobody fights for their ideas. Sometimes it feels we're not ambitious enough"</p>
<p>We've created a false choice:</p>
<p><strong>Option A:</strong> Hire nice, humble people → Get a room full of diffidence</p>
<p><strong>Option B:</strong> Tolerate brilliant assholes → Get results but destroy morale</p>
<p>Is this a true dichotomy?</p>
<hr />
<p>Were the assholes effective <em>because</em> they were assholes? Or <em>despite</em> being assholes?</p>
<p>What if the causality is backwards?</p>
<p>They had conviction. They were direct. They were ambitious. They pushed back on bad ideas.</p>
<p>They also happened to be assholes.</p>
<p>We saw correlation and assumed causation. We thought the cruelty was necessary for the conviction.</p>
<hr />
<p>Let me give you a counter-example.</p>
<p>Paul Mustiere spent 8 years at Palantir. I was his mentor when he interned. A few months ago, he joined Comand AI as Head of Engineering.</p>
<p>Paul is one of the highest-agency people I've ever worked with. He gets things done. He'll challenge your technical approach. He'll push back on bad ideas. He sets ambitious visions and rallies teams around them.</p>
<p>He's also genuinely humble. Low ego. Makes people around him better.</p>
<p>You don't have to choose between conviction and decency. Paul is living proof.</p>
<hr />
<p>But even if you believe tolerating assholes gets short-term results, what's the actual cost?</p>
<p>The good people who quietly leave. The collaborative culture you never build. The institutional knowledge that walks out the door. The junior engineers who learn that being right matters more than being decent.</p>
<p>You're not being pragmatic by ignoring human cost. You're taking on technical debt in your culture. And like all technical debt, it compounds.</p>
<hr />
<p>So here's the reframe:</p>
<p>Stop asking: "Should we hire assholes?"</p>
<p>Start asking: "How do we hire for conviction, directness, and ambition <em>without</em> hiring for cruelty, ego, and disrespect?"</p>
<p>Because these are separate traits.</p>
<p>You can have the physicist who challenges every assumption AND treats grad students with respect.</p>
<p>You can have the engineer who rewrites your architecture AND makes you feel good about the collaboration.</p>
<p>You can have the leader who sets an ambitious vision AND brings people along.</p>
<hr />
<p><strong>The framework for hiring:</strong></p>
<p>Must-haves:</p>
<ul>
<li>High conviction (will fight for what they believe)</li>
<li>Intellectual honesty (will change their mind when wrong)</li>
<li>Directness (will tell you the truth)</li>
<li>Ambition (wants to build something great)</li>
</ul>
<p>Deal-breakers:</p>
<ul>
<li>Making it personal</li>
<li>Cruelty for cruelty's sake</li>
<li>Ego-driven (caring more about being right than finding truth)</li>
<li>Disrespecting people even while disagreeing with ideas</li>
</ul>
<p>In an interview, this looks like:</p>
<ul>
<li>Someone who challenges your technical approach → good signal</li>
<li>
<p>Someone who challenges it and makes you feel stupid → red flag</p>
</li>
<li>
<p>Someone who says "I think you're wrong about this architecture" → high conviction</p>
</li>
<li>Someone who says "I can't believe you'd even consider that approach" → asshole</li>
</ul>
<hr />
<p>The unreasonable effectiveness of hiring assholes? It's a myth.</p>
<p>What's actually effective is hiring people with conviction.</p>
<p>Some of them happen to be assholes. That's not the part that makes them effective. That's the part that will eventually destroy your company.</p>
<p>Don't confuse the two.</p>
<hr />
<p>What's your experience? Have you seen companies successfully separate conviction from toxicity? Or is this just naive optimism?</p>
<hr />
<p><em>Implementing an FDE hiring program? See my <a href="https://anjor.github.io/fde-advisory-materials/">FDE Advisory Materials</a> for interview templates, scorecards, and detailed process guides.</em></p>
    
    
  </div>
</article>
      
        <article class="md-post md-post--excerpt">
  <header class="md-post__header">
    
    <div class="md-post__meta md-meta">
      <ul class="md-meta__list">
        <li class="md-meta__item">
          <time datetime="2025-11-11 00:00:00+00:00">2025/11/11</time></li>
        
          <li class="md-meta__item">
            in
            
              <a href="category/physics/" class="md-meta__link">physics</a>, 
              <a href="category/ai/" class="md-meta__link">ai</a></li>
        
        
          
          <li class="md-meta__item">
            
              9 min read
            
          </li>
        
        
      </ul>
      
    </div>
  </header>
  <div class="md-post__content md-typeset">
    <h2 id="building-a-gyrokinetics-code-without-reading-a-single-line-the-development-log"><a class="toclink" href="2025/11/11/building-a-gyrokinetics-code-without-reading-a-single-line-the-development-log/">Building a Gyrokinetics Code Without Reading a Single Line: The Development Log</a></h2>
<p>In the <a href="2025/11/05/testing-the-intelligence-explosion-can-ai-turn-one-physicist-into-a-research-team/">first post</a>, I outlined an experiment: can AI make intelligence a commodity in physics research? Two weeks of intensive work later, I have a modernized gyrokinetics code running on my laptop. The catch? I haven't read a single line of the ~3000 lines of JAX it contains.</p>
<p>This post documents what that process actually looked like—the workflow that emerged, the surprising failures, and the honest assessment of what worked and what didn't. If you're a physicist considering AI-assisted development, this is what you should know.</p>
<h3 id="the-constraints"><a class="toclink" href="2025/11/11/building-a-gyrokinetics-code-without-reading-a-single-line-the-development-log/#the-constraints">The Constraints</a></h3>
<p>After reaching out to the <a href="https://arxiv.org/abs/1505.02649">Viriato team</a>, it became clear I'd need HPC access I no longer have. So I decided to revive and modernize <a href="https://github.com/anjor/gandalf-original">GANDALF</a>, my PhD-era code. The constraint was simple: it needs to run on my M1 Pro MacBook.</p>
<p>I pointed Claude Code at the original GANDALF repository and the relevant chapter from my <a href="https://drum.lib.umd.edu/items/1362746c-af46-4fe9-a58c-8f1e25d43d36">PhD thesis</a>. I asked it to draft a plan and file GitHub issues for each step in that plan. It created a comprehensive set of issues covering everything from basic spectral methods to turbulence diagnostics.</p>
<p>The plan was straightforward: port from CUDA/Fortran to JAX with Metal backend, validate against known benchmarks, then extend to multi-ion physics.</p>
<p>I am not familiar with JAX. I also haven't written Fortran or CUDA in a decade. This would be a pure test of whether AI could bridge that gap.</p>
<h3 id="the-workflow-that-emerged"><a class="toclink" href="2025/11/11/building-a-gyrokinetics-code-without-reading-a-single-line-the-development-log/#the-workflow-that-emerged">The Workflow That Emerged</a></h3>
<p>The process settled into a rhythm:</p>
<ol>
<li>I ask Claude Code to pick the next issue from the GitHub tracker</li>
<li>Local Claude Code works on the issue and opens a PR</li>
<li>GitHub Claude (I installed Claude on the repo) reviews the PR</li>
<li>I selectively decide which feedback matters and what to ignore</li>
<li>Repeat</li>
</ol>
<p>The dual Claude setup wasn't planned—it emerged from necessity. I needed something different to review the code to keep it honest and prevent drift. Think of it as having two smart undergraduates check each other's work.</p>
<p>My role was purely validation through physics outputs. I modeled myself as a PhD advisor: I don't read the student's code, I look at their plots and ask if the physics makes sense. When something was wrong, I'd start by showing the plot. Often Claude would say something incorrect, and I'd need to push back with physics insights until we converged on the right answer.</p>
<p>This is critical: <strong>I validated entirely through physics, never through code inspection.</strong></p>
<h3 id="what-worked-surprisingly-well"><a class="toclink" href="2025/11/11/building-a-gyrokinetics-code-without-reading-a-single-line-the-development-log/#what-worked-surprisingly-well">What Worked Surprisingly Well</a></h3>
<p>Getting basic physics running was shockingly easy. Within the first week:</p>
<ul>
<li>Alfvén wave dispersion relations matched theory</li>
<li>Energy conservation held to machine precision</li>
<li>The Orszag-Tang vortex benchmark reproduced correctly</li>
</ul>
<p>Some of the more advanced benchmarks are still in progress—getting clean turbulent spectra with the expected -5/3 scaling has proven trickier and I'm still working on it.</p>
<p><strong>Figure 1</strong>: Orszag-Tang vortex at t=4.0 Alfvén times, showing the emergence of complex turbulent structures. The code correctly captures the vorticity filaments, current sheets, and magnetic field topology characteristic of 2D MHD turbulence.</p>
<p><img alt="Orszag-Tang Vortex Structures" src="assets/orszag_tang_structures.png" /></p>
<p><strong>Figure 2</strong>: Energy conservation over 4 Alfvén times. Total energy (black) remains constant to better than 0.01%, while kinetic (red) and magnetic (blue) energy exchange through turbulent dynamics. This level of conservation validates the spectral time-stepping algorithm.</p>
<p><img alt="Orszag-Tang Energy Conservation" src="assets/orszag_tang_energy_conservation.png" /></p>
<p><strong>Figure 3</strong>: Performance scaling on M1 Pro MacBook. A 128³ 3D simulation completes each Poisson solve in 28ms, putting useful turbulence simulations (hundreds of time steps) within reach of laptop hardware. The practical working range (green) shows what's actually feasible for iterative physics exploration.</p>
<p><img alt="Performance Scaling" src="assets/gandalf_performance_scaling.png" /></p>
<p>Claude wrote 100% of this code. Not 90%, not 95%—literally every line. I provided physics corrections when needed—catching things like KRMHD vs KREHM orderings, explaining why slow modes should be treated as passive scalars, and designing the validation tests themselves. But I never wrote a single line of code.</p>
<p>The speed was remarkable. Tasks that would have taken me days as a PhD student (debugging FFT boundary conditions, implementing spectral methods, setting up proper diagnostics) were done in hours.</p>
<h3 id="where-it-struggled-the-physics-numerics-boundary"><a class="toclink" href="2025/11/11/building-a-gyrokinetics-code-without-reading-a-single-line-the-development-log/#where-it-struggled-the-physics-numerics-boundary">Where It Struggled: The Physics-Numerics Boundary</a></h3>
<p>Advanced benchmarks proved much trickier. The problem wasn't coding—it was understanding the deep connection between physics and numerics.</p>
<h4 id="the-spectral-integrator-problem"><a class="toclink" href="2025/11/11/building-a-gyrokinetics-code-without-reading-a-single-line-the-development-log/#the-spectral-integrator-problem">The Spectral Integrator Problem</a></h4>
<p>My numerical algorithm is non-standard: it's a spectral method that gets linear physics exactly right by integrating those modes analytically. Claude saw "time integration" in the thesis, found "RK4" somewhere in the literature, and implemented bog-standard Runge-Kutta.</p>
<p>I had to explain multiple times: we're not approximating the linear physics, we're solving it exactly in Fourier space, then handling only the nonlinear coupling numerically. This is the whole point of the algorithm—it eliminates spurious damping of weakly damped kinetic modes.</p>
<p>Eventually it got there, but it took persistent correction. The AI didn't have the physical intuition for <em>why</em> this matters.</p>
<h4 id="the-forcing-coordinate-confusion"><a class="toclink" href="2025/11/11/building-a-gyrokinetics-code-without-reading-a-single-line-the-development-log/#the-forcing-coordinate-confusion">The Forcing Coordinate Confusion</a></h4>
<p>I specified that forcing should happen at large length scales: k=1,2 in Fourier space. Claude applied this condition to k_perp (because k_perp matters more than k_z in RMHD), but ended up forcing all k_z modes at those perpendicular wavenumbers. This caused immediate numerical instability—the simulation would blow up within a few time steps.</p>
<p>The fix required explaining the physics: we need to force specific 3D wavevectors, not all modes sharing a perpendicular wavenumber. This seems obvious in hindsight, but demonstrates how the AI can misunderstand the dimensional structure of the problem.</p>
<h4 id="navigating-the-stability-physics-trade-off"><a class="toclink" href="2025/11/11/building-a-gyrokinetics-code-without-reading-a-single-line-the-development-log/#navigating-the-stability-physics-trade-off">Navigating the Stability-Physics Trade-off</a></h4>
<p>When tuning simulations, Claude's intuition about the forcing-dissipation balance was consistently off, but in a subtle way that reveals something about how physicists think versus how AIs think.</p>
<p>As a physicist, you're always trying to extract maximum physics from your computational box. You want to maximize the inertial range to get a clean power law spectrum. This means running as close to the edge of numerical instability as possible. A simulation that produces beautiful physics for 20 Alfvén times and then blows up at 25 Alfvén times is <em>perfect</em>—you use the data from the first 20 time units. The code is a tool to do physics; it's not important on its own.</p>
<p>Claude's instinct was the opposite: make the simulation stable and robust. When it saw signs of instability, it would suggest increasing dissipation (which kills your inertial range) or reducing forcing amplitude (which weakens the physics you're trying to study). These are technically valid numerical choices, but they optimize for the wrong thing.</p>
<p>The right approach is to tune parameters to get as close to instability as possible without crossing the line. This requires physical intuition about what's actually happening in the simulation, not just numerical stability analysis.</p>
<h3 id="november-9-the-40-day"><a class="toclink" href="2025/11/11/building-a-gyrokinetics-code-without-reading-a-single-line-the-development-log/#november-9-the-40-day">November 9: The $40 Day</a></h3>
<p>The usage data tells a story. Most days cost $2-10. November 9 cost $40.</p>
<p>That was the day I tried to get nonlinear turbulence running properly. The simulation would run, but the physics was wrong in subtle ways. Energy would cascade, but not to the right scales. Heating rates would be off by factors of 2-3. Spectra would show the right scaling but wrong amplitudes.</p>
<p>The problem was that nonlinear turbulence requires <em>everything</em> to be right: the forcing must excite the correct modes, the dissipation must operate at the right scales, the time-stepping must preserve important invariants, and the diagnostics must actually measure what you think they're measuring.</p>
<p>I shifted from Sonnet to Opus hoping for better physics reasoning. It helped marginally, but I kept hitting limits. The AI could implement each piece correctly in isolation, but struggled to see how they fit together into a coherent physical picture.</p>
<p>We're still working on this. Some problems just take time, even with AI assistance.</p>
<h3 id="the-skills-that-actually-mattered"><a class="toclink" href="2025/11/11/building-a-gyrokinetics-code-without-reading-a-single-line-the-development-log/#the-skills-that-actually-mattered">The Skills That Actually Mattered</a></h3>
<p>Here's what surprised me: I didn't use my tech background at all. I didn't debug code, suggest algorithms, or catch Python syntax errors.</p>
<p>What I did use:</p>
<p><strong>Physics intuition</strong>: Knowing when results are physically wrong, even if numerically stable. Understanding that spectral pile-up means one thing while energy conservation violations mean something else entirely. Recognizing that a simulation optimized for stability is often a simulation optimized away from interesting physics.</p>
<p><strong>Applied AI intuition</strong>: Designing the dual-Claude review pattern. Structuring the workflow around incremental validation through physics benchmarks. Understanding AI failure modes and building guardrails around them. Knowing when to push the AI harder versus when to step in with physics corrections.</p>
<p>This second skill is crucial and under-discussed. It's not prompt engineering—it's something closer to understanding how to architect human-AI collaboration at the systems level.</p>
<h3 id="the-replicability-question"><a class="toclink" href="2025/11/11/building-a-gyrokinetics-code-without-reading-a-single-line-the-development-log/#the-replicability-question">The Replicability Question</a></h3>
<p>A friend asked: how much of an "n of 1" are you? Could a physics PhD with zero coding background do this?</p>
<p>Honest answer: <strong>not yet, at least not with the current setup.</strong></p>
<p>The bottleneck isn't coding ability—the AI handles that. The bottleneck is catching physics-numerics errors before they compound. By the time you see wrong results, you're often many commits deep into a wrong path.</p>
<p>A physicist without coding experience wouldn't know to set up the dual-Claude review pattern, wouldn't think to validate incrementally through physics benchmarks, wouldn't catch the spectral integrator mistake until much later.</p>
<p>Could this be taught? Could I package the workflow into something a pure physicist could use? I genuinely don't know. That's an open question.</p>
<h3 id="the-honest-productivity-assessment"><a class="toclink" href="2025/11/11/building-a-gyrokinetics-code-without-reading-a-single-line-the-development-log/#the-honest-productivity-assessment">The Honest Productivity Assessment</a></h3>
<p>The original GANDALF took me 6-7 months to build as a PhD student, working full-time. The new version took 30 days as a side project.</p>
<p>But this isn't quite an apples-to-apples comparison:</p>
<ul>
<li>PhD me was less experienced, had never written serious scientific code before</li>
<li>Current me could probably write this faster by hand than PhD me could</li>
<li>This is part-time work vs full-time</li>
</ul>
<p>Even accounting for these factors, the productivity gain is real. I'd estimate <strong>5-10x faster than I could have done solo</strong>, even with my current skills.</p>
<p>But it's not "intelligence as a commodity" yet. It's more like having an exceptionally capable research assistant who never gets tired, never forgets papers they've read, and can implement complex numerics at 2am without complaint.</p>
<p>The creativity, problem selection, and physics intuition remain entirely human. The AI amplifies what you already know; it doesn't replace knowing things.</p>
<h3 id="whats-next"><a class="toclink" href="2025/11/11/building-a-gyrokinetics-code-without-reading-a-single-line-the-development-log/#whats-next">What's Next</a></h3>
<p>The code is ready. The benchmarks are passing (mostly). The parameter space is mapped.</p>
<p>But there's an intermediate step: we're writing a proper journal paper documenting GANDALF itself. Using another Claude-assisted workflow in the <a href="https://github.com/anjor/gandalf-paper">gandalf-paper repository</a>, we're producing a comprehensive code paper targeting the Journal of Plasma Physics. This uses a different set of AI agents specialized for scientific writing—latex-equations, literature-curator, benchmark-analyst, physics-narrator, and code-documentor—working together to produce publication-quality text.</p>
<p>Then comes the actual physics test: can we discover something genuinely new about multi-ion turbulent heating? Can this AI-augmented approach produce insights worthy of publication as a second paper?</p>
<p>The next post will document that process—the physics investigation itself, what worked, what failed, and whether this experiment ultimately validates or refutes the intelligence explosion hypothesis.</p>
<h3 id="the-data"><a class="toclink" href="2025/11/11/building-a-gyrokinetics-code-without-reading-a-single-line-the-development-log/#the-data">The Data</a></h3>
<p>For transparency, here's what this cost in Claude API usage:</p>
<ul>
<li>Total: $307.19 over 16 active days (spanning 30 calendar days)</li>
<li>Average per active day: $19.20</li>
<li>Peak day (Nov 9, wrestling with nonlinear turbulence): $41.88</li>
<li>Total tokens processed: 522M</li>
</ul>
<p>Compared to my computational budget ($10K), this is negligible. Compared to the cost of hiring a programmer for a month, this is absurdly cheap. The constraint isn't money—it's my time to direct the work and validate the physics.</p>
<hr />
<h4 id="acknowledgements"><a class="toclink" href="2025/11/11/building-a-gyrokinetics-code-without-reading-a-single-line-the-development-log/#acknowledgements">Acknowledgements</a></h4>
<p>Thanks to the Claude team at Anthropic for building tools that actually work for technical research. And to everyone who's been following along with skeptical but curious questions—you're helping me think through what this means.</p>
    
    
  </div>
</article>
      
        <article class="md-post md-post--excerpt">
  <header class="md-post__header">
    
    <div class="md-post__meta md-meta">
      <ul class="md-meta__list">
        <li class="md-meta__item">
          <time datetime="2025-11-05 00:00:00+00:00">2025/11/05</time></li>
        
          <li class="md-meta__item">
            in
            
              <a href="category/physics/" class="md-meta__link">physics</a>, 
              <a href="category/ai/" class="md-meta__link">ai</a></li>
        
        
          
          <li class="md-meta__item">
            
              3 min read
            
          </li>
        
        
      </ul>
      
    </div>
  </header>
  <div class="md-post__content md-typeset">
    <h2 id="testing-the-intelligence-explosion-can-ai-turn-one-physicist-into-a-research-team"><a class="toclink" href="2025/11/05/testing-the-intelligence-explosion-can-ai-turn-one-physicist-into-a-research-team/">Testing the Intelligence Explosion: Can AI Turn One Physicist Into a Research Team?</a></h2>
<p>The <a href="https://situational-awareness.ai/from-agi-to-superintelligence/">intelligence explosion hypothesis</a> claims that AI will make intelligence a commodity—as accessible as electricity or compute. If true, this fundamentally changes how science is done. A single PI could effectively command dozens or even hundreds of smart undergraduates, limited only by their ability to direct rather than execute research.</p>
<p>I decided to test this claim in the domain I know something about: plasma astrophysics. And it was a fun excuse to do some physics again :).</p>
<h3 id="the-experiment"><a class="toclink" href="2025/11/05/testing-the-intelligence-explosion-can-ai-turn-one-physicist-into-a-research-team/#the-experiment">The Experiment</a></h3>
<p>After a decade away from active physics research, I'm attempting something that would typically require a small research group: identify an unsolved problem in gyrokinetic turbulence, develop computational tools to attack it, and produce publishable results. The difference? Instead of an advisor and collaborators, I am working with <a href="https://claude.ai">Claude</a>.</p>
<p>The mental model is crucial here. I'm not expecting the AI to be creative or to have deep physics intuition. Instead, I'm using it as an exceptionally capable undergraduate—one who can implement complex numerical schemes at 2am, never forgets a paper they've read, and can iterate on code without getting frustrated. The creativity, problem selection, and physics intuition remain human responsibilities.</p>
<h3 id="the-process-so-far"><a class="toclink" href="2025/11/05/testing-the-intelligence-explosion-can-ai-turn-one-physicist-into-a-research-team/#the-process-so-far">The Process So Far</a></h3>
<p>The journey began with a comprehensive literature survey. Claude and I reviewed ~50 papers from 2019-2024 on gyrokinetic turbulence, identifying several promising research directions. The key criteria: numerically tractable, genuinely unsolved, and building on recent breakthroughs.</p>
<p>I selected the problem: <strong>How do multiple ion species affect the helicity barrier and heating partition in collisionless plasmas?</strong> This extends recent work by <a href="https://www.pnas.org/doi/10.1073/pnas.1813913116">Meyrand et al. (2019)</a> on plasma echoes and the <a href="https://www.nature.com/articles/s41550-022-01624-z">helicity barrier mechanism</a> (Squire et al. 2022) to the astrophysically relevant case of solar wind with H⁺, He²⁺, and trace heavy ions. This is a natural extension of my own PhD research, and therefore seemed like fertile testing ground.</p>
<p>Next came tool selection. After discussions with the <a href="https://arxiv.org/abs/1505.02649">Viriato team</a>, it became clear that modernizing my PhD-era code GANDALF was the right approach. Not because it was the best code, but because I understood its physics assumptions deeply enough to guide the AI effectively.</p>
<p>This is where things got interesting. Using Claude Code, we rebuilt <a href="https://github.com/anjor/gandalf">GANDALF from scratch in JAX</a>, targeting Apple Silicon's Metal backend. In two weeks, we had:
- Reproduced the Orszag-Tang vortex benchmark
- Confirmed the -5/3 turbulent spectrum
- Validated energy conservation to machine precision</p>
<p>The AI wrote ~90% of the code. I provided physics corrections, caught subtle errors (KRMHD vs KREHM orderings), and designed the validation tests. My original <a href="https://drum.lib.umd.edu/items/1362746c-af46-4fe9-a58c-8f1e25d43d36">PhD thesis</a> provided the theoretical framework.</p>
<p>This entire journey—from literature survey to working code—has taken just two weeks (I started a month ago, but took a 2 week holiday). To put this in context, it took me ~6 months to write the original version of <a href="https://github.com/anjor/gandalf-original">Gandalf</a>. I did have an advantage on the literature review bit since I already knew it to some degree from the last time I did it.</p>
<h3 id="what-this-means"><a class="toclink" href="2025/11/05/testing-the-intelligence-explosion-can-ai-turn-one-physicist-into-a-research-team/#what-this-means">What This Means</a></h3>
<p>If this experiment succeeds—if we can produce a legitimate physics result worthy of publication—it suggests the intelligence explosion hypothesis has merit, at least for well-defined technical domains. The bottleneck shifts from execution to direction, from coding to physics insight.</p>
<p>But there are caveats. This only works because I can recognize when the physics is wrong, design meaningful computational experiments, and interpret results in context. The AI amplifies expertise; it doesn't replace it.</p>
<h3 id="whats-next"><a class="toclink" href="2025/11/05/testing-the-intelligence-explosion-can-ai-turn-one-physicist-into-a-research-team/#whats-next">What's Next</a></h3>
<p>We're now approaching the critical test: discovering something genuinely new about multi-ion turbulent heating. The computational framework is ready. The parameter space is mapped. The next posts will document whether an AI-augmented physicist can produce real scientific insights, and what that process actually looks like when physics intuition meets artificial intelligence.</p>
<p>Stay tuned for the story of writing a modern gyrokinetics code with an AI partner, complete with the failures, surprises, and occasional moments when the machine suggests something I hadn't considered.</p>
<h4 id="acknowledgements"><a class="toclink" href="2025/11/05/testing-the-intelligence-explosion-can-ai-turn-one-physicist-into-a-research-team/#acknowledgements">Acknowledgements</a></h4>
<p>I would like to thank <a href="https://www-thphys.physics.ox.ac.uk/people/AlexanderSchekochihin/">Alex Schekochihin</a> and <a href="https://nse.mit.edu/people/nuno-f-loureiro/">Nuno Loureiro</a> for helping me brainstorm this project, and pushing me to actually spend some cycles on it. I am forever in debt of <a href="https://sites.google.com/view/bdorland/milestones">Bill Dorland</a> for teaching me to push the boundaries of physics research using new and improved computing capabilities. </p>
    
    
  </div>
</article>
      
        <article class="md-post md-post--excerpt">
  <header class="md-post__header">
    
    <div class="md-post__meta md-meta">
      <ul class="md-meta__list">
        <li class="md-meta__item">
          <time datetime="2025-07-12 00:00:00+00:00">2025/07/12</time></li>
        
          <li class="md-meta__item">
            in
            
              <a href="category/career/" class="md-meta__link">career</a></li>
        
        
          
          <li class="md-meta__item">
            
              1 min read
            
          </li>
        
        
      </ul>
      
    </div>
  </header>
  <div class="md-post__content md-typeset">
    <h2 id="reflection"><a class="toclink" href="2025/07/12/reflection/">Reflection</a></h2>
<p>Career decisions are hard. </p>
<p>I have pivoted my career a few times now. First time was about a decade ago when I switched from academia to industry and from physics to tech. 
It was a difficult decision. I was leaving behind something I had obsessed over for 17 years for the complete unknown. In hindsight it seems like such a crazy decision -- I didn't know much about Palantir. 
I really enjoyed all my interviews (I remember the questions and the interviewers a decade since) - this was the main positive signal.  And the culture (as much as I could glean from the interviews) had a lot of similarities with academia, it felt familiar.</p>
<p>Boy was I fortunate. The 7 years I spent at Palantir defined the professional me. It taught me so many things -- technical, organisational, traits in people one should value and much more. 
It gave me the opportunity to wear many hats and grow stochastically.</p>
<p>Palantir gave me the opportunity and the courage to try new things. Leaving after 7 years was bittersweet - it was time for something new, but I missed my home.</p>
<p>The last 15-16 months have been very different. I have been trying to find the thing that
keeps me engaged, makes me obsessed. I wouldn't say I have found it yet, but I am working
on it. </p>
    
    
  </div>
</article>
      
        <article class="md-post md-post--excerpt">
  <header class="md-post__header">
    
    <div class="md-post__meta md-meta">
      <ul class="md-meta__list">
        <li class="md-meta__item">
          <time datetime="2025-07-05 00:00:00+00:00">2025/07/05</time></li>
        
          <li class="md-meta__item">
            in
            
              <a href="category/hiring/" class="md-meta__link">hiring</a></li>
        
        
          
          <li class="md-meta__item">
            
              5 min read
            
          </li>
        
        
      </ul>
      
    </div>
  </header>
  <div class="md-post__content md-typeset">
    <h2 id="the-database-selection-trap-why-your-technical-interviews-might-be-testing-the-wrong-things"><a class="toclink" href="2025/07/05/the-database-selection-trap-why-your-technical-interviews-might-be-testing-the-wrong-things/">The Database Selection Trap: Why Your Technical Interviews Might Be Testing the Wrong Things</a></h2>
<p>I recently watched a talented engineer fail a system design interview, and it made me question everything I thought I knew about technical hiring.</p>
<p>The candidate was asked to design a data model for a food delivery platform. They chose PostgreSQL. When the requirements evolved—millions of drivers, real-time location updates, flexible schemas—they couldn't pivot to NoSQL. Despite perfect nudges from the interviewer, they remained stuck.</p>
<p>Here's what haunted me: In any real engineering role, this person would have thrived. They'd have teammates suggesting alternatives. They'd have design reviews. They'd have documentation and prior art to reference.</p>
<p>But in that interview room, artificially isolated from every resource that makes modern engineering possible, they failed.</p>
<p>This isn't a story about lowering the bar. It's about recognizing that many of our "standard" technical interviews are testing the wrong things entirely.</p>
<h3 id="the-comfort-of-cargo-cult-interviews"><a class="toclink" href="2025/07/05/the-database-selection-trap-why-your-technical-interviews-might-be-testing-the-wrong-things/#the-comfort-of-cargo-cult-interviews">The Comfort of Cargo Cult Interviews</a></h3>
<p>We've all been there. You're tasked with building a hiring process, so you do what seems logical: look at what successful companies do and copy it. Google does system design interviews? So do we. Facebook does algorithm challenges? Add it to the list.</p>
<p>But here's the problem: we copy the form without understanding the function.</p>
<p>That database selection question? It made perfect sense... until I asked myself what we were actually testing:
- Can this person independently choose the right database in isolation?
- Or can this person build great systems in a collaborative environment?</p>
<p>These are fundamentally different skills. And only one of them matters for the job.</p>
<h3 id="the-three-interview-traps-that-filter-out-great-engineers"><a class="toclink" href="2025/07/05/the-database-selection-trap-why-your-technical-interviews-might-be-testing-the-wrong-things/#the-three-interview-traps-that-filter-out-great-engineers">The Three Interview Traps That Filter Out Great Engineers</a></h3>
<p>After auditing dozens of hiring processes, I've identified three common traps that eliminate potentially excellent engineers for the wrong reasons:</p>
<h4 id="1-the-isolation-trap"><a class="toclink" href="2025/07/05/the-database-selection-trap-why-your-technical-interviews-might-be-testing-the-wrong-things/#1-the-isolation-trap">1. The Isolation Trap</a></h4>
<p><strong>The Setup:</strong> Candidate must solve everything alone, from first principles, without any external resources.</p>
<p><strong>The Problem:</strong> This isn't how engineering works. Ever. Modern engineering is collaborative, iterative, and builds on existing knowledge. The best engineers aren't those who can reinvent everything in isolation—they're those who can leverage their team and tools effectively.</p>
<p><strong>Real Example:</strong> A senior engineer with 10 years of experience couldn't remember the exact syntax for a specific PostgreSQL window function. In reality, they'd look it up in 30 seconds. In the interview, they struggled for 10 minutes and lost confidence.</p>
<h4 id="2-the-perfection-trap"><a class="toclink" href="2025/07/05/the-database-selection-trap-why-your-technical-interviews-might-be-testing-the-wrong-things/#2-the-perfection-trap">2. The Perfection Trap</a></h4>
<p><strong>The Setup:</strong> One significant stumble means failure, regardless of overall performance.</p>
<p><strong>The Problem:</strong> Engineering is about recovery and iteration, not perfection. Some of the best engineers I've worked with are great precisely because they recognize mistakes quickly and course-correct effectively. But our interviews often punish any deviation from the "perfect" answer.</p>
<p><strong>Real Example:</strong> A candidate designed 90% of an excellent solution but made one architectural decision that would have caused scaling issues. Instead of seeing if they could identify and fix it with feedback (like they would in a real design review), they were marked down significantly.</p>
<h4 id="3-the-specific-knowledge-trap"><a class="toclink" href="2025/07/05/the-database-selection-trap-why-your-technical-interviews-might-be-testing-the-wrong-things/#3-the-specific-knowledge-trap">3. The Specific Knowledge Trap</a></h4>
<p><strong>The Setup:</strong> Testing specific technical knowledge rather than fundamental thinking.</p>
<p><strong>The Problem:</strong> Technology changes. What matters is engineering judgment, learning ability, and problem-solving approach. But we often test whether someone memorized the specific technologies we happen to use today.</p>
<p><strong>Real Example:</strong> A brilliant engineer "failed" because they weren't familiar with Kafka. They understood event-driven architectures perfectly and had used RabbitMQ extensively. Given a week on the job, they'd be productive with Kafka. But the interview didn't capture that.</p>
<h3 id="a-better-way-design-interviews-that-mirror-reality"><a class="toclink" href="2025/07/05/the-database-selection-trap-why-your-technical-interviews-might-be-testing-the-wrong-things/#a-better-way-design-interviews-that-mirror-reality">A Better Way: Design Interviews That Mirror Reality</a></h3>
<p>The solution isn't to make interviews easier. It's to make them more realistic. Here's a framework I use with my clients:</p>
<h4 id="step-1-start-with-role-reality"><a class="toclink" href="2025/07/05/the-database-selection-trap-why-your-technical-interviews-might-be-testing-the-wrong-things/#step-1-start-with-role-reality">Step 1: Start With Role Reality</a></h4>
<p>Before designing any interview, answer these questions:
- What does a typical day look like for this engineer?
- What resources do they have access to?
- How do they collaborate with others?
- What does "great performance" actually look like?</p>
<h4 id="step-2-map-backwards-to-interview-signals"><a class="toclink" href="2025/07/05/the-database-selection-trap-why-your-technical-interviews-might-be-testing-the-wrong-things/#step-2-map-backwards-to-interview-signals">Step 2: Map Backwards to Interview Signals</a></h4>
<p>For each critical skill, ask:
- What's the minimal signal we need to assess this?
- How can we test this in a way that mirrors reality?
- What support would they have in the real role?</p>
<h4 id="step-3-build-in-collaboration-and-iteration"><a class="toclink" href="2025/07/05/the-database-selection-trap-why-your-technical-interviews-might-be-testing-the-wrong-things/#step-3-build-in-collaboration-and-iteration">Step 3: Build in Collaboration and Iteration</a></h4>
<p>Instead of testing isolated perfection, test realistic excellence:
- Allow candidates to ask clarifying questions (like they would with stakeholders)
- Provide feedback and see how they incorporate it (like in code review)
- Let them reference documentation for syntax (like they would with Google)
- Focus on their thinking process, not memorized solutions</p>
<h3 id="case-study-redesigning-the-system-design-interview"><a class="toclink" href="2025/07/05/the-database-selection-trap-why-your-technical-interviews-might-be-testing-the-wrong-things/#case-study-redesigning-the-system-design-interview">Case Study: Redesigning the System Design Interview</a></h3>
<p>Here's how we transformed that problematic database interview:</p>
<p><strong>Old Version:</strong>
"Design a data model for a food delivery system. Choose your database and justify it."</p>
<p><strong>New Version:</strong>
"Let's design a data model for a food delivery system together. Here's our current scale and requirements. As we go, I'll play the role of your teammate and share what we've learned from our existing systems."</p>
<p>The key changes:
1. <strong>Collaborative framing</strong> - "together" and "teammate" set the tone
2. <strong>Living requirements</strong> - Requirements evolve during the discussion, like real projects
3. <strong>Historical context</strong> - They can ask about existing systems and constraints
4. <strong>Focus on reasoning</strong> - We care more about how they think through trade-offs than their initial choice</p>
<p>The result? We started identifying engineers who would excel in our actual environment, not those who could perform in artificial interview conditions.</p>
<h3 id="the-hidden-cost-of-bad-interviews"><a class="toclink" href="2025/07/05/the-database-selection-trap-why-your-technical-interviews-might-be-testing-the-wrong-things/#the-hidden-cost-of-bad-interviews">The Hidden Cost of Bad Interviews</a></h3>
<p>Every time we filter out a great engineer because they stumbled on an artificial constraint, we're not just losing a potential hire. We're:
- Reinforcing biases toward certain backgrounds (those who've practiced these specific interview formats)
- Extending our hiring timeline as we search for unicorns who excel at interviews AND engineering
- Building teams that optimize for interview performance over actual job performance</p>
<h3 id="your-next-step-the-one-question-audit"><a class="toclink" href="2025/07/05/the-database-selection-trap-why-your-technical-interviews-might-be-testing-the-wrong-things/#your-next-step-the-one-question-audit">Your Next Step: The One-Question Audit</a></h3>
<p>Pick one question from your current interview process. Just one. Now ask yourself:</p>
<p><em>"If a strong engineer failed this specific question but excelled at everything else, would I bet they'd fail in the actual role?"</em></p>
<p>If the answer is no, you're testing the wrong thing.</p>
<h3 id="the-path-forward"><a class="toclink" href="2025/07/05/the-database-selection-trap-why-your-technical-interviews-might-be-testing-the-wrong-things/#the-path-forward">The Path Forward</a></h3>
<p>Great hiring isn't about finding engineers who can solve puzzles in isolation. It's about identifying those who will thrive in your specific environment, collaborate effectively with your team, and deliver value to your customers.</p>
<p>That means designing interviews that test for reality, not ritual.</p>
<p>Start with one interview. Make it 10% more realistic. See what changes.</p>
<p>Because somewhere out there is an engineer who would be fantastic on your team but can't remember if MongoDB uses documents or collections in the heat of an interview.</p>
<p>Do you really want to miss out on them because of that?</p>
<hr />
<p><em>Implementing an FDE hiring program? See my <a href="https://anjor.github.io/fde-advisory-materials/">FDE Advisory Materials</a> for interview templates, scorecards, and detailed process guides.</em></p>
    
    
  </div>
</article>
      
      
        
          



<nav class="md-pagination">
  <span class="md-pagination__current">1</span> <a class="md-pagination__link" href="page/2/">2</a> <a class="md-pagination__link" href="page/3/">3</a>
</nav>
        
      
    </div>
  </div>

          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright &copy; 2023 Anjor Kanekar
    </div>
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
        
<div class="md-social">
  
    
    
    
    
      
      
    
    <a href="https://twitter.com/__anjor" target="_blank" rel="noopener" title="twitter.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M459.4 151.7c.3 4.5.3 9.1.3 13.6 0 138.7-105.6 298.6-298.6 298.6-59.5 0-114.7-17.2-161.1-47.1 8.4 1 16.6 1.3 25.3 1.3 49.1 0 94.2-16.6 130.3-44.8-46.1-1-84.8-31.2-98.1-72.8 6.5 1 13 1.6 19.8 1.6 9.4 0 18.8-1.3 27.6-3.6-48.1-9.7-84.1-52-84.1-103v-1.3c14 7.8 30.2 12.7 47.4 13.3-28.3-18.8-46.8-51-46.8-87.4 0-19.5 5.2-37.4 14.3-53C87.4 130.8 165 172.4 252.1 176.9c-1.6-7.8-2.6-15.9-2.6-24C249.5 95.1 296.3 48 354.4 48c30.2 0 57.5 12.7 76.7 33.1 23.7-4.5 46.5-13.3 66.6-25.3-7.8 24.4-24.4 44.8-46.1 57.8 21.1-2.3 41.6-8.1 60.4-16.2-14.3 20.8-32.2 39.3-52.6 54.3"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://github.com/anjor" target="_blank" rel="noopener" title="github.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://www.linkedin.com/in/anjor-kanekar/" target="_blank" rel="noopener" title="www.linkedin.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3M135.4 416H69V202.2h66.5V416zM102.2 96a38.5 38.5 0 1 1 0 77 38.5 38.5 0 1 1 0-77m282.1 320h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9z"/></svg>
    </a>
  
    
    
    
    
    <a href="/feed_rss_updated.xml" target="_blank" rel="noopener" title="Subscribe to our RSS Feed" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6.18 15.64a2.18 2.18 0 0 1 2.18 2.18C8.36 19 7.38 20 6.18 20 5 20 4 19 4 17.82a2.18 2.18 0 0 1 2.18-2.18M4 4.44A15.56 15.56 0 0 1 19.56 20h-2.83A12.73 12.73 0 0 0 4 7.27zm0 5.66a9.9 9.9 0 0 1 9.9 9.9h-2.83A7.07 7.07 0 0 0 4 12.93z"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      
      <script id="__config" type="application/json">{"annotate": null, "base": "..", "features": ["navigation.indexes", "navigation.tabs"], "search": "../assets/javascripts/workers/search.2c215733.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../assets/javascripts/bundle.79ae519e.min.js"></script>
      
    
  </body>
</html>